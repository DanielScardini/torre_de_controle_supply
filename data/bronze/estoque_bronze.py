# Databricks notebook source
# MAGIC %md
# MAGIC # Processamento de Estoque - Camada Bronze
# MAGIC
# MAGIC Este notebook processa dados de estoque de lojas e dep√≥sitos para a camada Bronze,
# MAGIC seguindo o padr√£o Medallion Architecture e as melhores pr√°ticas Python.
# MAGIC
# MAGIC **Author**: Torre de Controle Supply Chain  
# MAGIC **Date**: 2024  
# MAGIC **Purpose**: Processar estoque de lojas e dep√≥sitos para an√°lise de disponibilidade e planejamento de abastecimento

# COMMAND ----------

# MAGIC %md
# MAGIC ## Imports e Configura√ß√£o Inicial

# COMMAND ----------

from datetime import datetime, timedelta, date
from typing import Optional, Union

from pyspark.sql import SparkSession, DataFrame
from pyspark.sql import functions as F
from pytz import timezone

# =============================================================================
# CONFIGURA√á√ïES GLOBAIS
# =============================================================================

# Nome das tabelas de destino na camada Bronze
TABELA_BRONZE_ESTOQUE_LOJA: str = "databox.bcg_comum.supply_bronze_estoque_lojas"
TABELA_BRONZE_ESTOQUE_CD: str = "databox.bcg_comum.supply_bronze_estoque_cds"

# Timezone S√£o Paulo (GMT-3)
TIMEZONE_SP = timezone('America/Sao_Paulo')

# =============================================================================
# CONFIGURA√á√ïES DE DESENVOLVIMENTO
# =============================================================================

# Usar samples para desenvolvimento (evitar gasto de processamento)
USAR_SAMPLES: bool = True  # Alterar para False em produ√ß√£o
SAMPLE_SIZE: int = 100000  # Tamanho do sample para desenvolvimento

# Inicializa√ß√£o do Spark
spark = SparkSession.builder.appName("estoque_bronze").getOrCreate()

# Data de processamento (hoje)
hoje = datetime.now(TIMEZONE_SP)
hoje_str = hoje.strftime("%Y-%m-%d")
hoje_int = int(hoje.strftime("%Y%m%d"))

print(f"üìÖ Data de processamento: {hoje}")
print(f"üìù Data string: {hoje_str}")
print(f"üî¢ Data int: {hoje_int}")
print(f"üåç Timezone: {TIMEZONE_SP}")

# =============================================================================
# CONFIGURA√á√ïES DE PROCESSAMENTO
# =============================================================================
print("=" * 80)
print("üîß CONFIGURA√á√ïES DE PROCESSAMENTO:")
print(f"  ‚Ä¢ Usar Samples: {USAR_SAMPLES}")
if USAR_SAMPLES:
    print(f"  ‚Ä¢ Tamanho do Sample: {SAMPLE_SIZE:,} registros")
    print("  ‚Ä¢ ‚ö†Ô∏è  MODO DESENVOLVIMENTO - Alterar USAR_SAMPLES=False para produ√ß√£o")
else:
    print("  ‚Ä¢ ‚úÖ MODO PRODU√á√ÉO - Processamento completo")
print("=" * 80)

# COMMAND ----------

# MAGIC %md
# MAGIC ## Carregamento de Dados de Estoque - Lojas
# MAGIC
# MAGIC Este bloco carrega dados de estoque das lojas ativas (`DsEstoqueLojaDeposito == "L"`).
# MAGIC Os dados incluem informa√ß√µes de disponibilidade, classifica√ß√£o ABC e m√©tricas de DDE
# MAGIC para an√°lise de qualidade do estoque.

# COMMAND ----------

print("üè™ Processando estoque de LOJAS...")

# Carregar dados de estoque das lojas
estoque_lojas_df = (
    spark.table("data_engineering_prd.app_logistica.gi_boss_qualidade_estoque")
    .filter(F.col("DtAtual") >= hoje_str)
    .filter(F.col("StLoja") == "ATIVA")
    .filter(F.col("DsEstoqueLojaDeposito") == "L")
)

# Aplicar sample se configurado para desenvolvimento
if USAR_SAMPLES:
    print(f"üî¨ Aplicando sample de {SAMPLE_SIZE:,} registros LOJAS para desenvolvimento...")
    estoque_lojas_df = estoque_lojas_df.sample(fraction=0.1, seed=42).limit(SAMPLE_SIZE)

estoque_lojas_df = estoque_lojas_df.cache()

print(f"üìä Registros de estoque LOJAS carregados: {estoque_lojas_df.count()}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Carregamento de Dados de Estoque - Dep√≥sitos (CDs)
# MAGIC
# MAGIC Este bloco carrega dados de estoque dos dep√≥sitos (`DsEstoqueLojaDeposito == "D"`).
# MAGIC Os dados incluem informa√ß√µes de disponibilidade nos centros de distribui√ß√£o
# MAGIC para an√°lise de capacidade de abastecimento.

# COMMAND ----------

print("üè≠ Processando estoque de DEP√ìSITOS (CDs)...")

# Carregar dados de estoque dos dep√≥sitos
estoque_cds_df = (
    spark.table("data_engineering_prd.app_logistica.gi_boss_qualidade_estoque")
    .filter(F.col("DtAtual") >= hoje_str)
    .filter(F.col("DsEstoqueLojaDeposito") == "D")
)

# Aplicar sample se configurado para desenvolvimento
if USAR_SAMPLES:
    print(f"üî¨ Aplicando sample de {SAMPLE_SIZE:,} registros CDs para desenvolvimento...")
    estoque_cds_df = estoque_cds_df.sample(fraction=0.1, seed=42).limit(SAMPLE_SIZE)

estoque_cds_df = estoque_cds_df.cache()

print(f"üìä Registros de estoque CDs carregados: {estoque_cds_df.count()}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Transforma√ß√£o e Limpeza dos Dados - Lojas
# MAGIC
# MAGIC Este bloco aplica transforma√ß√µes e limpeza nos dados de estoque das lojas,
# MAGIC incluindo sele√ß√£o de colunas relevantes, c√°lculos de m√©tricas e remo√ß√£o de duplicatas.

# COMMAND ----------

print("üîÑ Transformando dados de estoque LOJAS...")

# Transformar e limpar dados de estoque das lojas
estoque_lojas_processado_df = (
    estoque_lojas_df
    .select(
        "CdFilial", 
        "CdSku",
        "DsSku",
        "DsSetor",
        "DsCurva",
        "DsCurvaAbcLoja",
        "StLinha",
        "DsObrigatorio",
        "DsVoltagem",
        F.col("DsTipoEntrega").alias("TipoEntrega"),
        F.col("CdEstoqueFilialAbastecimento").alias("QtdEstoqueCDVinculado"),
        (F.col("VrTotalVv")/F.col("VrVndCmv")).alias("DDE"),
        F.col("QtEstoqueBoaOff").alias("EstoqueLoja"),
        F.col("DsFaixaDde").alias("ClassificacaoDDE"),
        F.col("data_ingestao"),
        F.date_format(F.col("data_ingestao"), "yyyy-MM-dd").alias("DtAtual")    
    )
    .dropDuplicates(["DtAtual", "CdSku", "CdFilial"])
    .withColumn("TipoEstoque", F.lit("LOJA"))
).cache()

print(f"‚úÖ Registros de estoque LOJAS processados: {estoque_lojas_processado_df.count()}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Transforma√ß√£o e Limpeza dos Dados - Dep√≥sitos
# MAGIC
# MAGIC Este bloco aplica transforma√ß√µes e limpeza nos dados de estoque dos dep√≥sitos,
# MAGIC incluindo sele√ß√£o de colunas relevantes e c√°lculos de m√©tricas.

# COMMAND ----------

print("üîÑ Transformando dados de estoque DEP√ìSITOS...")

# Transformar e limpar dados de estoque dos dep√≥sitos
estoque_cds_processado_df = (
    estoque_cds_df
    .select(
        "CdFilial", 
        "CdSku",
        "DsSku",
        "DsSetor",
        "DsCurva",
        "DsCurvaAbcLoja",
        "StLinha",
        "DsObrigatorio",
        "DsVoltagem",
        F.col("DsTipoEntrega").alias("TipoEntrega"),
        F.col("CdEstoqueFilialAbastecimento").alias("QtdEstoqueCDVinculado"),
        (F.col("VrTotalVv")/F.col("VrVndCmv")).alias("DDE"),
        F.col("QtEstoqueBoaOff").alias("EstoqueDeposito"),
        F.col("DsFaixaDde").alias("ClassificacaoDDE"),
        F.col("data_ingestao"),
        F.date_format(F.col("data_ingestao"), "yyyy-MM-dd").alias("DtAtual")    
    )
    .dropDuplicates(["DtAtual", "CdSku", "CdFilial"])
    .withColumn("TipoEstoque", F.lit("DEPOSITO"))
).cache()

print(f"‚úÖ Registros de estoque DEP√ìSITOS processados: {estoque_cds_processado_df.count()}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## An√°lise Estat√≠stica dos Dados
# MAGIC
# MAGIC Este bloco apresenta estat√≠sticas resumidas dos dados de estoque processados,
# MAGIC incluindo totais de registros, filiais √∫nicas, SKUs √∫nicos e distribui√ß√£o por tipo.

# COMMAND ----------

# Mostrar estat√≠sticas das lojas
print("üìà Estat√≠sticas de estoque LOJAS:")
estatisticas_lojas_df = estoque_lojas_processado_df.agg(
    F.count("*").alias("Total_Registros"),
    F.countDistinct("CdFilial").alias("Filiais_Unicas"),
    F.countDistinct("CdSku").alias("SKUs_Unicos"),
    F.sum("EstoqueLoja").alias("Estoque_Total"),
    F.avg("DDE").alias("DDE_Medio")
)

# display(estatisticas_lojas_df)

# Mostrar estat√≠sticas dos dep√≥sitos
print("üìà Estat√≠sticas de estoque DEP√ìSITOS:")
estatisticas_cds_df = estoque_cds_processado_df.agg(
    F.count("*").alias("Total_Registros"),
    F.countDistinct("CdFilial").alias("Filiais_Unicas"),
    F.countDistinct("CdSku").alias("SKUs_Unicos"),
    F.sum("EstoqueDeposito").alias("Estoque_Total"),
    F.avg("DDE").alias("DDE_Medio")
)

# display(estatisticas_cds_df)

# COMMAND ----------

# MAGIC %md
# MAGIC ## Adi√ß√£o de Metadados de Processamento - Lojas
# MAGIC
# MAGIC Este bloco adiciona colunas de metadados ao DataFrame de estoque das lojas,
# MAGIC como `DataHoraProcessamento`, `DataProcessamento`, `FonteDados` e `VersaoProcessamento`.

# COMMAND ----------

print("üíæ Adicionando metadados de processamento LOJAS...")

# Adicionar metadados de processamento
estoque_lojas_com_metadados_df = estoque_lojas_processado_df.withColumn(
    "DataHoraProcessamento",
    F.current_timestamp()
).withColumn(
    "DataProcessamento",
    F.current_date()
).withColumn(
    "FonteDados",
    F.lit("data_engineering_prd.app_logistica.gi_boss_qualidade_estoque")
).withColumn(
    "VersaoProcessamento",
    F.lit("1.0")
)

print(f"‚úÖ Metadados adicionados LOJAS. Total de registros: {estoque_lojas_com_metadados_df.count()}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Adi√ß√£o de Metadados de Processamento - Dep√≥sitos
# MAGIC
# MAGIC Este bloco adiciona colunas de metadados ao DataFrame de estoque dos dep√≥sitos,
# MAGIC como `DataHoraProcessamento`, `DataProcessamento`, `FonteDados` e `VersaoProcessamento`.

# COMMAND ----------

print("üíæ Adicionando metadados de processamento DEP√ìSITOS...")

# Adicionar metadados de processamento
estoque_cds_com_metadados_df = estoque_cds_processado_df.withColumn(
    "DataHoraProcessamento",
    F.current_timestamp()
).withColumn(
    "DataProcessamento",
    F.current_date()
).withColumn(
    "FonteDados",
    F.lit("data_engineering_prd.app_logistica.gi_boss_qualidade_estoque")
).withColumn(
    "VersaoProcessamento",
    F.lit("1.0")
)

print(f"‚úÖ Metadados adicionados DEP√ìSITOS. Total de registros: {estoque_cds_com_metadados_df.count()}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Salvamento na Camada Bronze - Lojas
# MAGIC
# MAGIC Este bloco salva o DataFrame de estoque das lojas na tabela Delta da camada Bronze,
# MAGIC utilizando o modo `overwrite` para garantir que a tabela seja sempre atualizada.

# COMMAND ----------

print(f"üíæ Salvando tabela {TABELA_BRONZE_ESTOQUE_LOJA} no modo overwrite...")

try:
    # Salvar na camada Bronze
    estoque_lojas_com_metadados_df.write \
        .format("delta") \
        .mode("overwrite") \
        .option("overwriteSchema", "true") \
        .saveAsTable(TABELA_BRONZE_ESTOQUE_LOJA)
    
    print(f"‚úÖ Tabela {TABELA_BRONZE_ESTOQUE_LOJA} salva com sucesso!")
    print(f"üìä Registros salvos LOJAS: {estoque_lojas_com_metadados_df.count()}")

except Exception as e:
    print(f"‚ùå Erro ao salvar tabela {TABELA_BRONZE_ESTOQUE_LOJA}: {str(e)}")
    raise

# COMMAND ----------

# MAGIC %md
# MAGIC ## Salvamento na Camada Bronze - Dep√≥sitos
# MAGIC
# MAGIC Este bloco salva o DataFrame de estoque dos dep√≥sitos na tabela Delta da camada Bronze,
# MAGIC utilizando o modo `overwrite` para garantir que a tabela seja sempre atualizada.

# COMMAND ----------

print(f"üíæ Salvando tabela {TABELA_BRONZE_ESTOQUE_CD} no modo overwrite...")

try:
    # Salvar na camada Bronze
    estoque_cds_com_metadados_df.write \
        .format("delta") \
        .mode("overwrite") \
        .option("overwriteSchema", "true") \
        .saveAsTable(TABELA_BRONZE_ESTOQUE_CD)
    
    print(f"‚úÖ Tabela {TABELA_BRONZE_ESTOQUE_CD} salva com sucesso!")
    print(f"üìä Registros salvos DEP√ìSITOS: {estoque_cds_com_metadados_df.count()}")

except Exception as e:
    print(f"‚ùå Erro ao salvar tabela {TABELA_BRONZE_ESTOQUE_CD}: {str(e)}")
    raise

# COMMAND ----------

# MAGIC %md
# MAGIC ## Valida√ß√£o das Tabelas Salvas
# MAGIC
# MAGIC Este bloco realiza uma leitura das tabelas rec√©m-salvas para verificar
# MAGIC seus schemas e exibir amostras dos dados, confirmando que o salvamento
# MAGIC foi bem-sucedido.

# COMMAND ----------

print(f"üîç Validando tabelas salvas...")

# Validar tabela de lojas
print("üìã Schema da tabela LOJAS:")
spark.table(TABELA_BRONZE_ESTOQUE_LOJA).printSchema()

# Validar tabela de dep√≥sitos
print("üìã Schema da tabela DEP√ìSITOS:")
spark.table(TABELA_BRONZE_ESTOQUE_CD).printSchema()

print("‚úÖ Valida√ß√£o conclu√≠da com sucesso!")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Limpeza de Cache
# MAGIC
# MAGIC Este bloco limpa o cache dos DataFrames para liberar mem√≥ria ap√≥s o processamento.

# COMMAND ----------

print("üßπ Limpando cache para liberar mem√≥ria...")

# Limpar cache
estoque_lojas_df.unpersist()
estoque_cds_df.unpersist()
estoque_lojas_processado_df.unpersist()
estoque_cds_processado_df.unpersist()

print("‚úÖ Cache limpo com sucesso!")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Resumo Final do Processamento
# MAGIC
# MAGIC Este bloco finaliza o notebook com um resumo das principais informa√ß√µes
# MAGIC do processamento, incluindo contagem de registros e tabelas de destino.

# COMMAND ----------

print("üéâ Processamento de estoque Bronze conclu√≠do com sucesso!")
print("=" * 80)
print("üìä RESUMO DO PROCESSAMENTO:")
print(f"  ‚Ä¢ Data de processamento: {hoje_str}")
print(f"  ‚Ä¢ Registros lojas: {estoque_lojas_com_metadados_df.count():,}")
print(f"  ‚Ä¢ Registros dep√≥sitos: {estoque_cds_com_metadados_df.count():,}")
print(f"  ‚Ä¢ Tabela lojas: {TABELA_BRONZE_ESTOQUE_LOJA}")
print(f"  ‚Ä¢ Tabela dep√≥sitos: {TABELA_BRONZE_ESTOQUE_CD}")
print("=" * 80)
print("‚úÖ PROCESSAMENTO CONCLU√çDO COM SUCESSO!")
print("üè™ Dados de estoque de lojas processados")
print("üè≠ Dados de estoque de dep√≥sitos processados")
print("üìä Estrutura: Filial x SKU x Data com m√©tricas de estoque")