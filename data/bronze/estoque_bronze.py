# Databricks notebook source
# MAGIC %md
# MAGIC # Processamento de Estoque - Camada Bronze
# MAGIC
# MAGIC Este notebook processa dados de estoque de lojas e dep√≥sitos para a camada Bronze,
# MAGIC seguindo o padr√£o Medallion Architecture e as melhores pr√°ticas Python.
# MAGIC
# MAGIC **Author**: Torre de Controle Supply Chain  
# MAGIC **Date**: 2024  
# MAGIC **Purpose**: Processar estoque de lojas e dep√≥sitos para an√°lise de disponibilidade e planejamento de abastecimento

# COMMAND ----------

# MAGIC %md
# MAGIC ## Configura√ß√µes de Ambiente via Widgets
# MAGIC
# MAGIC Este bloco cria widgets interativos para configurar o ambiente de execu√ß√£o.
# MAGIC Os widgets permitem alterar os par√¢metros diretamente na interface do Databricks.

# COMMAND ----------

# Criar widgets para configura√ß√µes
dbutils.widgets.dropdown("modo_execucao", "TEST", ["TEST", "RUN"], "Modo de Execu√ß√£o")
dbutils.widgets.dropdown("ambiente_tabela", "DEV", ["DEV", "PROD"], "Ambiente da Tabela")
dbutils.widgets.text("sample_size", "10000", "Tamanho do Sample (apenas para TEST)")

# Obter valores dos widgets
MODO_EXECUCAO = dbutils.widgets.get("modo_execucao")
AMBIENTE_TABELA = dbutils.widgets.get("ambiente_tabela")
SAMPLE_SIZE = int(dbutils.widgets.get("sample_size"))

print(f"üéõÔ∏è Widgets configurados:")
print(f"  ‚Ä¢ Modo de Execu√ß√£o: {MODO_EXECUCAO}")
print(f"  ‚Ä¢ Ambiente da Tabela: {AMBIENTE_TABELA}")
print(f"  ‚Ä¢ Tamanho do Sample: {SAMPLE_SIZE:,}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Imports e Configura√ß√£o Inicial

# COMMAND ----------

from datetime import datetime, timedelta, date
from typing import Optional, Union

from pyspark.sql import SparkSession, DataFrame
from pyspark.sql import functions as F
from pytz import timezone

# =============================================================================
# CONFIGURA√á√ïES GLOBAIS
# =============================================================================

# Nome das tabelas de destino na camada Bronze (parametrizado por ambiente)
TABELA_BRONZE_ESTOQUE_LOJA: str = f"databox.bcg_comum.supply_{AMBIENTE_TABELA.lower()}_estoque_lojas"
TABELA_BRONZE_ESTOQUE_CD: str = f"databox.bcg_comum.supply_{AMBIENTE_TABELA.lower()}_estoque_cds"

# Timezone S√£o Paulo (GMT-3)
TIMEZONE_SP = timezone('America/Sao_Paulo')

# =============================================================================
# CONFIGURA√á√ïES DE DESENVOLVIMENTO
# =============================================================================

# Usar samples baseado no modo de execu√ß√£o
USAR_SAMPLES: bool = (MODO_EXECUCAO == "TEST")

# Inicializa√ß√£o do Spark
spark = SparkSession.builder.appName("estoque_bronze").getOrCreate()

# Data de processamento (hoje)
hoje = datetime.now(TIMEZONE_SP)
hoje_str = hoje.strftime("%Y-%m-%d")
hoje_int = int(hoje.strftime("%Y%m%d"))

print(f"üìÖ Data de processamento: {hoje}")
print(f"üìù Data string: {hoje_str}")
print(f"üî¢ Data int: {hoje_int}")
print(f"üåç Timezone: {TIMEZONE_SP}")

# =============================================================================
# CONFIGURA√á√ïES DE PROCESSAMENTO
# =============================================================================
print("=" * 80)
print("üîß CONFIGURA√á√ïES DE PROCESSAMENTO:")
print(f"  ‚Ä¢ Modo de Execu√ß√£o: {MODO_EXECUCAO}")
print(f"  ‚Ä¢ Ambiente da Tabela: {AMBIENTE_TABELA}")
print(f"  ‚Ä¢ Tabela Lojas: {TABELA_BRONZE_ESTOQUE_LOJA}")
print(f"  ‚Ä¢ Tabela CDs: {TABELA_BRONZE_ESTOQUE_CD}")
print(f"  ‚Ä¢ Usar Samples: {USAR_SAMPLES}")
if USAR_SAMPLES:
    print(f"  ‚Ä¢ Tamanho do Sample: {SAMPLE_SIZE:,} registros")
    print("  ‚Ä¢ ‚ö†Ô∏è  MODO TEST - Usando samples para desenvolvimento")
else:
    print("  ‚Ä¢ ‚úÖ MODO RUN - Processamento completo")
print("=" * 80)

# COMMAND ----------

# MAGIC %md
# MAGIC ## Carregamento de Dados de Estoque - Lojas
# MAGIC
# MAGIC Este bloco carrega dados de estoque das lojas ativas (`DsEstoqueLojaDeposito == "L"`).
# MAGIC Os dados incluem informa√ß√µes de disponibilidade, classifica√ß√£o ABC e m√©tricas de DDE
# MAGIC para an√°lise de qualidade do estoque.

# COMMAND ----------

print("üè™ Processando estoque de LOJAS...")

# Carregar dados de estoque das lojas
estoque_lojas_df = (
    spark.table("data_engineering_prd.app_logistica.gi_boss_qualidade_estoque")
        .filter(F.col("DtAtual") >= hoje_str)
        .filter(F.col("StLoja") == "ATIVA")
        .filter(F.col("DsEstoqueLojaDeposito") == "L")
)

# Aplicar sample se configurado para desenvolvimento
if USAR_SAMPLES:
    print(f"üî¨ Aplicando sample de {SAMPLE_SIZE:,} registros LOJAS para desenvolvimento...")
    estoque_lojas_df = estoque_lojas_df.sample(fraction=0.1, seed=42).limit(SAMPLE_SIZE)

estoque_lojas_df = estoque_lojas_df.cache()

print(f"üìä Registros de estoque LOJAS carregados: {estoque_lojas_df.count()}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Carregamento de Dados de Estoque - Dep√≥sitos (CDs)
# MAGIC
# MAGIC Este bloco carrega dados de estoque dos dep√≥sitos (`DsEstoqueLojaDeposito == "D"`).
# MAGIC Os dados incluem informa√ß√µes de disponibilidade nos centros de distribui√ß√£o
# MAGIC para an√°lise de capacidade de abastecimento.

# COMMAND ----------

print("üè≠ Processando estoque de DEP√ìSITOS (CDs)...")

# Carregar dados de estoque dos dep√≥sitos
estoque_cds_df = (
    spark.table("data_engineering_prd.app_logistica.gi_boss_qualidade_estoque")
        .filter(F.col("DtAtual") >= hoje_str)
        .filter(F.col("DsEstoqueLojaDeposito") == "D")
)

# Aplicar sample se configurado para desenvolvimento
if USAR_SAMPLES:
    print(f"üî¨ Aplicando sample de {SAMPLE_SIZE:,} registros CDs para desenvolvimento...")
    estoque_cds_df = estoque_cds_df.sample(fraction=0.1, seed=42).limit(SAMPLE_SIZE)

estoque_cds_df = estoque_cds_df.cache()

print(f"üìä Registros de estoque CDs carregados: {estoque_cds_df.count()}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Transforma√ß√£o e Limpeza dos Dados - Lojas
# MAGIC
# MAGIC Este bloco aplica transforma√ß√µes e limpeza nos dados de estoque das lojas,
# MAGIC incluindo sele√ß√£o de colunas relevantes, c√°lculos de m√©tricas e remo√ß√£o de duplicatas.

# COMMAND ----------

print("üîÑ Transformando dados de estoque LOJAS...")

# Transformar e limpar dados de estoque das lojas
estoque_lojas_processado_df = (
    estoque_lojas_df
    .withColumn("TipoEstoque", F.lit("LOJA"))
    .withColumn("DDE", (F.col("VrTotalVv")/F.col("VrVndCmv")))
    .withColumn("DtAtual", F.date_format(F.col("data_ingestao"), "yyyy-MM-dd"))
    .dropDuplicates(["DtAtual", "CdSku", "CdFilial"]) # Garantir unicidade
).cache()

print(f"‚úÖ Registros de estoque LOJAS processados: {estoque_lojas_processado_df.count()}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Transforma√ß√£o e Limpeza dos Dados - Dep√≥sitos
# MAGIC
# MAGIC Este bloco aplica transforma√ß√µes e limpeza nos dados de estoque dos dep√≥sitos,
# MAGIC incluindo sele√ß√£o de colunas relevantes e c√°lculos de m√©tricas.

# COMMAND ----------

print("üîÑ Transformando dados de estoque DEP√ìSITOS...")

# Transformar e limpar dados de estoque dos dep√≥sitos
estoque_cds_processado_df = (
    estoque_cds_df
    .withColumn("TipoEstoque", F.lit("CD"))
    .withColumn("DDE", (F.col("VrTotalVv")/F.col("VrVndCmv")))
    .withColumn("DtAtual", F.date_format(F.col("data_ingestao"), "yyyy-MM-dd"))
    .dropDuplicates(["DtAtual", "CdSku", "CdFilial"]) # Garantir unicidade
).cache()

print(f"‚úÖ Registros de estoque DEP√ìSITOS processados: {estoque_cds_processado_df.count()}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Carregamento de Dados do GEF (Gest√£o de Estoque e Faturamento)
# MAGIC
# MAGIC Este bloco carrega dados do GEF que cont√™m informa√ß√µes estrat√©gicas de estoque,
# MAGIC incluindo estoque de seguran√ßa, lead time, cobertura, demanda e proje√ß√µes.
# MAGIC Estes dados ser√£o unidos com os dados de estoque das lojas e dep√≥sitos.

# COMMAND ----------

spark.table("databox.logistica_comum.gef_visao_estoque_lojas").limit(10).display()


# COMMAND ----------

print("üìä Carregando dados do GEF...")

# Carregar dados do GEF
gef_df = (
    spark.table("databox.logistica_comum.gef_visao_estoque_lojas")
    .select(
        F.col("CODIGO_ITEM").alias("CdSku"),
        F.col("FILIAL_AJ").alias("CdFilial"),
        F.col("DATA_ANALISE").alias("DtAtual"),
        F.col("ESTOQUE_SEGURANCA"),
        F.col("LEADTIME_MEDIO"),
        F.col("COBERTURA_ES_DIAS"),
        F.col("ESTOQUE_ALVO"),
        F.col("COBERTURA_ATUAL"),
        F.col("COBERTURA_ALVO"),
        F.col("DDV_SEM_OUTLIER"),
        F.col("DDV_FUTURO"),
        F.col("GRADE"),
        F.col("TRANSITO"),
        F.col("ESTOQUE_PROJETADO"),
        F.col("COBERTURA_ATUAL_C_TRANSITO_DIAS"),
        F.col("MEDIA_3"),
        F.col("MEDIA_6"),
        F.col("MEDIA_12"),
        F.col("DDV_SO"),
        F.col("DDV_CO"),
        F.col("CLUSTER_OBG"),
        F.col("CLUSTER_SUG")
    )
)

# Aplicar sample se configurado para desenvolvimento
if USAR_SAMPLES:
    print(f"üî¨ Aplicando sample de {SAMPLE_SIZE:,} registros GEF para desenvolvimento...")
    gef_df = gef_df.sample(fraction=0.1, seed=42).limit(SAMPLE_SIZE)

gef_df = gef_df.cache()

print(f"üìä Registros do GEF carregados: {gef_df.count()}")

# Mostrar amostra das datas para valida√ß√£o
print("üìÖ Valida√ß√£o do formato de datas no GEF:")
gef_df.select("DtAtual").distinct().orderBy("DtAtual").show(10, truncate=False)

# Valida√ß√£o de duplicatas nas chaves de join
print("üîç Validando chaves de join para evitar multiplica√ß√£o de registros...")

# Verificar duplicatas no GEF (incluindo data)
duplicatas_gef = gef_df.groupBy("CdFilial", "CdSku", "DtAtual").count().filter(F.col("count") > 1)
total_duplicatas_gef = duplicatas_gef.count()

print(f"üìä Valida√ß√£o de duplicatas GEF:")
print(f"  ‚Ä¢ Chaves duplicadas no GEF (Filial+SKU+DtAtual): {total_duplicatas_gef:,}")

if total_duplicatas_gef > 0:
    print("‚ö†Ô∏è  ATEN√á√ÉO: GEF cont√©m chaves duplicadas! Isso pode causar multiplica√ß√£o de registros.")
    print("üîß Solu√ß√£o: Remover duplicatas do GEF antes do join")
    
    # Remover duplicatas do GEF mantendo apenas o primeiro registro
    gef_df = gef_df.dropDuplicates(["CdFilial", "CdSku", "DtAtual"]).cache()
    print(f"‚úÖ Duplicatas removidas do GEF. Novos registros: {gef_df.count():,}")
else:
    print("‚úÖ GEF n√£o cont√©m chaves duplicadas")

# Verificar duplicatas no estoque das lojas (incluindo data)
duplicatas_lojas = estoque_lojas_processado_df.groupBy("CdFilial", "CdSku", "DtAtual").count().filter(F.col("count") > 1)
total_duplicatas_lojas = duplicatas_lojas.count()

print(f"üìä Valida√ß√£o de duplicatas Estoque Lojas:")
print(f"  ‚Ä¢ Chaves duplicadas no estoque lojas (Filial+SKU+DtAtual): {total_duplicatas_lojas:,}")

if total_duplicatas_lojas > 0:
    print("‚ö†Ô∏è  ATEN√á√ÉO: Estoque lojas cont√©m chaves duplicadas!")
else:
    print("‚úÖ Estoque lojas n√£o cont√©m chaves duplicadas")

# Verificar duplicatas no estoque dos dep√≥sitos (incluindo data)
duplicatas_cds = estoque_cds_processado_df.groupBy("CdFilial", "CdSku", "DtAtual").count().filter(F.col("count") > 1)
total_duplicatas_cds = duplicatas_cds.count()

print(f"üìä Valida√ß√£o de duplicatas Estoque Dep√≥sitos:")
print(f"  ‚Ä¢ Chaves duplicadas no estoque dep√≥sitos (Filial+SKU+DtAtual): {total_duplicatas_cds:,}")

if total_duplicatas_cds > 0:
    print("‚ö†Ô∏è  ATEN√á√ÉO: Estoque dep√≥sitos cont√©m chaves duplicadas!")
else:
    print("‚úÖ Estoque dep√≥sitos n√£o cont√©m chaves duplicadas")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Join dos Dados de Estoque com GEF - Lojas
# MAGIC
# MAGIC Este bloco realiza o join entre os dados de estoque das lojas e os dados do GEF,
# MAGIC enriquecendo as informa√ß√µes de estoque com m√©tricas estrat√©gicas de gest√£o.

# COMMAND ----------

print("üîó Realizando join entre estoque LOJAS e dados GEF (Filial + SKU + Data)...")

# Valida√ß√£o antes do join
registros_antes_join_lojas = estoque_lojas_processado_df.count()
registros_gef = gef_df.count()

print(f"üìä Valida√ß√£o antes do join LOJAS:")
print(f"  ‚Ä¢ Registros estoque lojas: {registros_antes_join_lojas:,}")
print(f"  ‚Ä¢ Registros GEF: {registros_gef:,}")
print(f"  ‚Ä¢ Chaves de join: CdFilial + CdSku + DtAtual")

# Join entre estoque das lojas e dados do GEF (incluindo data)
estoque_lojas_com_gef_df = (
    estoque_lojas_processado_df
    .join(
        gef_df,
        on=["CdFilial", "CdSku", "DtAtual"],
        how="left"
    )
    .withColumn("TipoEstoque", F.lit("LOJA"))
).cache()

# Valida√ß√£o ap√≥s o join
registros_apos_join_lojas = estoque_lojas_com_gef_df.count()
registros_com_match_lojas = estoque_lojas_com_gef_df.filter(F.col("ESTOQUE_SEGURANCA").isNotNull()).count()
percentual_match_lojas = (registros_com_match_lojas / registros_apos_join_lojas) * 100

print(f"üìä Valida√ß√£o ap√≥s join LOJAS:")
print(f"  ‚Ä¢ Registros ap√≥s join: {registros_apos_join_lojas:,}")
print(f"  ‚Ä¢ Registros com match GEF: {registros_com_match_lojas:,}")
print(f"  ‚Ä¢ Percentual de match: {percentual_match_lojas:.2f}%")
print(f"  ‚Ä¢ Aumento de registros: {registros_apos_join_lojas - registros_antes_join_lojas:,}")

if registros_apos_join_lojas != registros_antes_join_lojas:
    print("‚ö†Ô∏è  ATEN√á√ÉO: Join gerou aumento de registros!")
else:
    print("‚úÖ Join manteve quantidade de registros (left join correto)")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Join dos Dados de Estoque com GEF - Dep√≥sitos
# MAGIC
# MAGIC Este bloco realiza o join entre os dados de estoque dos dep√≥sitos e os dados do GEF,
# MAGIC enriquecendo as informa√ß√µes de estoque com m√©tricas estrat√©gicas de gest√£o.

# COMMAND ----------

print("üîó Realizando join entre estoque DEP√ìSITOS e dados GEF (Filial + SKU + Data)...")

# Valida√ß√£o antes do join
registros_antes_join_cds = estoque_cds_processado_df.count()

print(f"üìä Valida√ß√£o antes do join DEP√ìSITOS:")
print(f"  ‚Ä¢ Registros estoque dep√≥sitos: {registros_antes_join_cds:,}")
print(f"  ‚Ä¢ Registros GEF: {registros_gef:,}")
print(f"  ‚Ä¢ Chaves de join: CdFilial + CdSku + DtAtual")

# Carregar plano de abastecimento para agregar GEF das lojas por CD
print("üìã Carregando plano de abastecimento para agregar GEF das lojas por CD...")

TABELA_PLANO_ABASTECIMENTO = "data_engineering_prd.context_logistica.planoabastecimento"

plano_df = (
    spark.table(TABELA_PLANO_ABASTECIMENTO)
    .select("CdFilialEntrega", "CdLoja")
    .distinct()
)

print(f"üìä Registros do plano de abastecimento: {plano_df.count()}")

# Agregar GEF das lojas por CD atrav√©s do plano de abastecimento
print("üîÑ Agregando m√©tricas GEF das lojas por CD...")

# Join GEF com plano por CdFilial (loja)
gef_plano_df = gef_df.join(
    plano_df,
    on=gef_df["CdFilial"] == plano_df["CdLoja"],
    how="inner"
)

# Group by CdFilialEntrega (CD) - somando todas as m√©tricas GEF
gef_cd_agregado_df = gef_plano_df.groupBy("CdFilialEntrega", "CdSku", "DtAtual").agg(
    F.sum("ESTOQUE_SEGURANCA").alias("ESTOQUE_SEGURANCA"),
    F.sum("LEADTIME_MEDIO").alias("LEADTIME_MEDIO"),
    F.sum("COBERTURA_ES_DIAS").alias("COBERTURA_ES_DIAS"),
    F.sum("ESTOQUE_ALVO").alias("ESTOQUE_ALVO"),
    F.sum("COBERTURA_ATUAL").alias("COBERTURA_ATUAL"),
    F.sum("COBERTURA_ALVO").alias("COBERTURA_ALVO"),
    F.sum("DDV_SEM_OUTLIER").alias("DDV_SEM_OUTLIER"),
    F.sum("DDV_FUTURO").alias("DDV_FUTURO"),
    F.sum("GRADE").alias("GRADE"),
    F.sum("TRANSITO").alias("TRANSITO"),
    F.sum("ESTOQUE_PROJETADO").alias("ESTOQUE_PROJETADO"),
    F.sum("COBERTURA_ATUAL_C_TRANSITO_DIAS").alias("COBERTURA_ATUAL_C_TRANSITO_DIAS"),
    F.sum("MEDIA_3").alias("MEDIA_3"),
    F.sum("MEDIA_6").alias("MEDIA_6"),
    F.sum("MEDIA_9").alias("MEDIA_9"),
    F.sum("MEDIA_12").alias("MEDIA_12"),
    F.sum("DDV_SO").alias("DDV_SO"),
    F.sum("DDV_CO").alias("DDV_CO"),
    F.sum("CLUSTER_OBG").alias("CLUSTER_OBG"),  # Count de lojas atendidas
    F.sum("CLUSTER_SUG").alias("CLUSTER_SUG")   # Count de lojas atendidas
).withColumnRenamed("CdFilialEntrega", "CdFilial")

print(f"üìä Registros GEF agregados por CD: {gef_cd_agregado_df.count()}")

# Join entre estoque dos dep√≥sitos e GEF agregado por CD
estoque_cds_com_gef_df = (
    estoque_cds_processado_df
    .join(
        gef_cd_agregado_df,
        on=["CdFilial", "CdSku", "DtAtual"],
        how="left"
    )
    .withColumn("TipoEstoque", F.lit("CD"))
).cache()

# Valida√ß√£o ap√≥s o join
registros_apos_join_cds = estoque_cds_com_gef_df.count()
registros_com_match_cds = estoque_cds_com_gef_df.filter(F.col("ESTOQUE_SEGURANCA").isNotNull()).count()
percentual_match_cds = (registros_com_match_cds / registros_apos_join_cds) * 100

print(f"üìä Valida√ß√£o ap√≥s join DEP√ìSITOS:")
print(f"  ‚Ä¢ Registros ap√≥s join: {registros_apos_join_cds:,}")
print(f"  ‚Ä¢ Registros com match GEF: {registros_com_match_cds:,}")
print(f"  ‚Ä¢ Percentual de match: {percentual_match_cds:.2f}%")
print(f"  ‚Ä¢ Aumento de registros: {registros_apos_join_cds - registros_antes_join_cds:,}")

if registros_apos_join_cds != registros_antes_join_cds:
    print("‚ö†Ô∏è  ATEN√á√ÉO: Join gerou aumento de registros!")
else:
    print("‚úÖ Join manteve quantidade de registros (left join correto)")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Adi√ß√£o de Metadados de Processamento - Lojas Enriquecidas
# MAGIC
# MAGIC Este bloco adiciona colunas de metadados ao DataFrame de estoque das lojas enriquecido com GEF.

# COMMAND ----------

print("üíæ Adicionando metadados de processamento LOJAS + GEF...")

# Adicionar metadados de processamento
estoque_lojas_gef_com_metadados_df = estoque_lojas_com_gef_df.withColumn(
    "DataHoraProcessamento",
    F.current_timestamp()
).withColumn(
    "DataProcessamento",
    F.current_date()
).withColumn(
    "FonteDados",
    F.lit("data_engineering_prd.app_logistica.gi_boss_qualidade_estoque + databox.logistica_comum.gef_visao_estoque_lojas")
).withColumn(
    "VersaoProcessamento",
    F.lit("1.0")
)

print(f"‚úÖ Metadados adicionados LOJAS + GEF. Total de registros: {estoque_lojas_gef_com_metadados_df.count()}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Adi√ß√£o de Metadados de Processamento - Dep√≥sitos Enriquecidos
# MAGIC
# MAGIC Este bloco adiciona colunas de metadados ao DataFrame de estoque dos dep√≥sitos enriquecido com GEF.

# COMMAND ----------

print("üíæ Adicionando metadados de processamento DEP√ìSITOS + GEF...")

# Adicionar metadados de processamento
estoque_cds_gef_com_metadados_df = estoque_cds_com_gef_df.withColumn(
    "DataHoraProcessamento",
    F.current_timestamp()
).withColumn(
    "DataProcessamento",
    F.current_date()
).withColumn(
    "FonteDados",
    F.lit("data_engineering_prd.app_logistica.gi_boss_qualidade_estoque + databox.logistica_comum.gef_visao_estoque_lojas + data_engineering_prd.context_logistica.planoabastecimento")
).withColumn(
    "VersaoProcessamento",
    F.lit("1.0")
)

print(f"‚úÖ Metadados adicionados DEP√ìSITOS + GEF. Total de registros: {estoque_cds_gef_com_metadados_df.count()}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Salvamento na Camada Bronze - Lojas Enriquecidas
# MAGIC
# MAGIC Este bloco salva o DataFrame de estoque das lojas enriquecido com dados do GEF.

# COMMAND ----------

print(f"üíæ Salvando tabela {TABELA_BRONZE_ESTOQUE_LOJA} (enriquecida com GEF) no modo overwrite...")

try:
    # Salvar na camada Bronze
    estoque_lojas_gef_com_metadados_df.write \
        .format("delta") \
        .mode("overwrite") \
        .option("overwriteSchema", "true") \
        .saveAsTable(TABELA_BRONZE_ESTOQUE_LOJA)
    
    print(f"‚úÖ Tabela {TABELA_BRONZE_ESTOQUE_LOJA} salva com sucesso!")
    print(f"üìä Registros salvos LOJAS + GEF: {estoque_lojas_gef_com_metadados_df.count()}")

except Exception as e:
    print(f"‚ùå Erro ao salvar tabela {TABELA_BRONZE_ESTOQUE_LOJA}: {str(e)}")
    raise

# COMMAND ----------

# MAGIC %md
# MAGIC ## Salvamento na Camada Bronze - Dep√≥sitos Enriquecidos
# MAGIC
# MAGIC Este bloco salva o DataFrame de estoque dos dep√≥sitos enriquecido com dados do GEF.

# COMMAND ----------

print(f"üíæ Salvando tabela {TABELA_BRONZE_ESTOQUE_CD} (enriquecida com GEF) no modo overwrite...")

try:
    # Salvar na camada Bronze
    estoque_cds_gef_com_metadados_df.write \
        .format("delta") \
        .mode("overwrite") \
        .option("overwriteSchema", "true") \
        .saveAsTable(TABELA_BRONZE_ESTOQUE_CD)
    
    print(f"‚úÖ Tabela {TABELA_BRONZE_ESTOQUE_CD} salva com sucesso!")
    print(f"üìä Registros salvos DEP√ìSITOS + GEF: {estoque_cds_gef_com_metadados_df.count()}")

except Exception as e:
    print(f"‚ùå Erro ao salvar tabela {TABELA_BRONZE_ESTOQUE_CD}: {str(e)}")
    raise

# COMMAND ----------

# MAGIC %md
# MAGIC ## Valida√ß√£o das Tabelas Salvas
# MAGIC
# MAGIC Este bloco realiza uma leitura das tabelas rec√©m-salvas para verificar
# MAGIC seus schemas e exibir amostras dos dados, confirmando que o salvamento
# MAGIC foi bem-sucedido.

# COMMAND ----------

print(f"üîç Validando tabelas salvas...")

# Validar tabela de lojas
print("üìã Schema da tabela LOJAS:")
spark.table(TABELA_BRONZE_ESTOQUE_LOJA).printSchema()

# Validar tabela de dep√≥sitos
print("üìã Schema da tabela DEP√ìSITOS:")
spark.table(TABELA_BRONZE_ESTOQUE_CD).printSchema()

print("‚úÖ Valida√ß√£o conclu√≠da com sucesso!")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Limpeza de Cache
# MAGIC
# MAGIC Este bloco limpa o cache dos DataFrames para liberar mem√≥ria ap√≥s o processamento.

# COMMAND ----------

print("üßπ Limpando cache para liberar mem√≥ria...")

# Limpar cache
estoque_lojas_df.unpersist()
estoque_cds_df.unpersist()
estoque_lojas_processado_df.unpersist()
estoque_cds_processado_df.unpersist()
gef_df.unpersist()
estoque_lojas_com_gef_df.unpersist()
estoque_cds_com_gef_df.unpersist()

print("‚úÖ Cache limpo com sucesso!")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Resumo Final do Processamento
# MAGIC
# MAGIC Este bloco finaliza o notebook com um resumo das principais informa√ß√µes
# MAGIC do processamento, incluindo contagem de registros e tabelas de destino.

# COMMAND ----------

print("üéâ Processamento de estoque Bronze conclu√≠do com sucesso!")
print("=" * 80)
print("üìä RESUMO DO PROCESSAMENTO:")
print(f"  ‚Ä¢ Data de processamento: {hoje_str}")
print(f"  ‚Ä¢ Registros lojas + GEF: {estoque_lojas_gef_com_metadados_df.count():,}")
print(f"  ‚Ä¢ Registros dep√≥sitos + GEF: {estoque_cds_gef_com_metadados_df.count():,}")
print(f"  ‚Ä¢ Tabela lojas: {TABELA_BRONZE_ESTOQUE_LOJA}")
print(f"  ‚Ä¢ Tabela dep√≥sitos: {TABELA_BRONZE_ESTOQUE_CD}")
print("=" * 80)
print("‚úÖ PROCESSAMENTO CONCLU√çDO COM SUCESSO!")
print("üè™ Dados de estoque de lojas processados e enriquecidos com GEF")
print("üè≠ Dados de estoque de dep√≥sitos processados e enriquecidos com GEF")
print("üìä Estrutura: Filial x SKU x Data com m√©tricas de estoque + dados estrat√©gicos GEF")
print("üîó Join realizado com dados do GEF (CdFilial + CdSku + DtAtual) para enriquecimento estrat√©gico")
print("üìÖ Formato de data: yyyy-MM-dd (convertido de DATA_ANALISE do GEF)")
