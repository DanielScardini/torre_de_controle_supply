# COMMAND ----
# MAGIC %md
# MAGIC # Processamento de Vendas - Camada Bronze
# MAGIC
# MAGIC Este notebook processa dados de vendas online e offline para a camada Bronze,
# MAGIC seguindo o padr√£o Medallion Architecture.
# MAGIC
# MAGIC **Objetivo**: Consolidar vendas de todos os canais em uma base √∫nica para an√°lise de demanda e planejamento de estoque.

# COMMAND ----
# MAGIC %md
# MAGIC ## 1. Configura√ß√£o Inicial e Imports
# MAGIC
# MAGIC Configura√ß√£o das bibliotecas necess√°rias e defini√ß√£o das vari√°veis globais para o processamento.
# MAGIC Esta etapa √© fundamental para garantir que todas as depend√™ncias estejam dispon√≠veis e as configura√ß√µes estejam corretas.

# COMMAND ----
from datetime import datetime, timedelta, date
from typing import Optional, Union

from pyspark.sql import SparkSession, DataFrame
from pyspark.sql import functions as F
from pytz import timezone

# =============================================================================
# CONFIGURA√á√ïES GLOBAIS
# =============================================================================

# Nome da tabela de destino na camada Bronze
TABELA_BRONZE_VENDAS: str = "databox.bcg_comum.supply_bronze_vendas_90d_on_off"

# Timezone S√£o Paulo (GMT-3)
TIMEZONE_SP = timezone('America/Sao_Paulo')

# Inicializa√ß√£o do Spark
spark = SparkSession.builder.appName("vendas_bronze").getOrCreate()

# Data de processamento (ontem)
hoje = datetime.now(TIMEZONE_SP) - timedelta(days=1)
hoje_str = hoje.strftime("%Y-%m-%d")
hoje_int = int(hoje.strftime("%Y%m%d"))

print(f"üìÖ Data de processamento: {hoje}")
print(f"üìù Data string: {hoje_str}")
print(f"üî¢ Data int: {hoje_int}")
print(f"üåç Timezone: {TIMEZONE_SP}")

# COMMAND ----
# MAGIC %md
# MAGIC ## 2. C√°lculo da Data de In√≠cio
# MAGIC
# MAGIC Calculamos a data de in√≠cio baseada nos √∫ltimos 90 dias para garantir que temos hist√≥rico suficiente
# MAGIC para an√°lise de tend√™ncias e padr√µes de demanda. Esta configura√ß√£o permite ajustes flex√≠veis no per√≠odo de an√°lise.

# COMMAND ----
# Configura√ß√£o do per√≠odo de an√°lise
dias_retrocesso = 90

# Valida√ß√£o do par√¢metro
if dias_retrocesso < 0:
    raise ValueError("dias_retrocesso deve ser positivo")

# C√°lculo da data de in√≠cio
hoje_dt = datetime.now(TIMEZONE_SP)
data_inicio = hoje_dt - timedelta(days=dias_retrocesso)
data_inicio_int = int(data_inicio.strftime("%Y%m%d"))

print(f"üìä Data de in√≠cio calculada: {data_inicio}")
print(f"‚è∞ Dias de retrocesso: {dias_retrocesso}")
print(f"üìÖ Data in√≠cio: {data_inicio}")
print(f"üî¢ Data in√≠cio int: {data_inicio_int}")

# Definir data_inicio_str para uso posterior
data_inicio_str = data_inicio.strftime("%Y-%m-%d")

# DataFrame de exemplo para verifica√ß√£o
df_exemplo = spark.range(1).select(
    F.lit(data_inicio).alias("data_inicio"),
    F.lit(data_inicio_int).alias("data_inicio_int"),
    F.lit(90).alias("dias_retrocesso")
)

display(df_exemplo)

# COMMAND ----
# MAGIC %md
# MAGIC ## 3. Carregamento de Vendas Offline (Loja F√≠sica)
# MAGIC
# MAGIC Carregamos as vendas de loja f√≠sica da tabela vendafaturadarateada.
# MAGIC Esta etapa √© cr√≠tica pois representa a maior parte do volume de vendas da empresa.
# MAGIC Filtramos apenas registros v√°lidos (sem saldos, valores positivos) para garantir qualidade dos dados.

# COMMAND ----
print(f"üè™ Processando vendas OFFLINE de {data_inicio_int} at√© {hoje_int}")

# Carregar tabela de vendas rateadas (offline)
vendas_rateadas_offline_df = (
    spark.table("app_venda.vendafaturadarateada")
    .filter(F.col("NmEstadoMercadoria") != '1 - SALDO')
    .filter(F.col("NmTipoNegocio") == 'LOJA FISICA')
    .filter(
        F.col("DtAprovacao").between(data_inicio_int, hoje_int)
        & (F.col("VrOperacao") >= 0)
        & (F.col("VrCustoContabilFilialSku") >= 0)
    )
)

print(f"üìä Registros rateados carregados: {vendas_rateadas_offline_df.count()}")

# COMMAND ----
# MAGIC %md
# MAGIC ## 4. Carregamento de Quantidades (Vendas N√£o Rateadas)
# MAGIC
# MAGIC Carregamos as quantidades vendidas da tabela vendafaturadanaorateada.
# MAGIC Esta tabela cont√©m as quantidades f√≠sicas vendidas, essencial para an√°lise de demanda.
# MAGIC O join com a tabela rateada nos permite ter tanto valores quanto quantidades.

# COMMAND ----
# Carregar tabela de vendas n√£o rateadas para quantidade
vendas_nao_rateadas_df = (
    spark.table("app_venda.vendafaturadanaorateada")
    .filter(F.col("QtMercadoria") >= 0)
)

print(f"üìà Registros n√£o rateados carregados: {vendas_nao_rateadas_df.count()}")

# COMMAND ----
# MAGIC %md
# MAGIC ## 5. Unifica√ß√£o dos Dados Offline
# MAGIC
# MAGIC Realizamos o join entre as tabelas rateadas e n√£o rateadas para obter uma vis√£o completa das vendas offline.
# MAGIC Esta etapa √© fundamental para garantir que temos tanto os valores financeiros quanto as quantidades f√≠sicas.

# COMMAND ----
# Unificar dados e aplicar transforma√ß√µes
vendas_offline_unificadas_df = (
    vendas_rateadas_offline_df
    .join(vendas_nao_rateadas_df.select("ChaveFatos", "QtMercadoria"), on="ChaveFatos")
    .withColumn(
        "year_month",
        F.date_format(
            F.to_date(F.col("DtAprovacao").cast("string"), "yyyyMMdd"), 
            "yyyyMM"
        ).cast("int")
    )
    .withColumnRenamed("CdFilialVenda", "CdFilial")
    .withColumn(
        "DtAtual",
        F.date_format(
            F.to_date(F.col("DtAprovacao").cast("string"), "yyyyMMdd"), 
            "yyyy-MM-dd"
        )
    )
)

print(f"üîó Registros ap√≥s join: {vendas_offline_unificadas_df.count()}")

# COMMAND ----
# MAGIC %md
# MAGIC ## 6. Agrega√ß√£o das Vendas Offline
# MAGIC
# MAGIC Agregamos as vendas offline por filial, SKU e data para obter m√©tricas consolidadas.
# MAGIC Esta agrega√ß√£o √© necess√°ria para eliminar duplicatas e criar uma base limpa para an√°lise.

# COMMAND ----
# Agregar por filial, SKU e data
vendas_offline_agregadas_df = (
    vendas_offline_unificadas_df.groupBy(
        "DtAtual",
        "year_month",
        "CdSkuLoja",
        "CdFilial",
    )
    .agg(
        F.sum("VrOperacao").alias("Receita"),
        F.sum("QtMercadoria").alias("QtMercadoria"),
        F.sum("VrCustoContabilFilialSku").alias("Custo")
    )
)

print(f"üìä Registros ap√≥s agrega√ß√£o: {vendas_offline_agregadas_df.count()}")

# COMMAND ----
# MAGIC %md
# MAGIC ## 7. Cria√ß√£o da Grade Completa de Datas
# MAGIC
# MAGIC Criamos uma grade completa de datas para garantir que todas as combina√ß√µes filial-SKU tenham registros
# MAGIC para todos os dias do per√≠odo, mesmo quando n√£o houve vendas. Isso √© essencial para an√°lises de demanda.

# COMMAND ----
# Criar grade completa de datas
calendario_df = (
    spark.range(1)
    .select(
        F.explode(
            F.sequence(
                F.to_date(F.lit(str(data_inicio_int)), "yyyyMMdd"),
                F.to_date(F.lit(str(hoje_int)), "yyyyMMdd"),
                F.expr("interval 1 day")
            )
        ).alias("DtAtual_date")
    )
)

# Conjunto de chaves (Filial x SKU) para loja f√≠sica
chaves_filial_sku_df = (
    vendas_offline_unificadas_df
    .select("CdFilial", "CdSkuLoja")
    .dropDuplicates()
)

print(f"üîë Chaves √∫nicas (Filial x SKU): {chaves_filial_sku_df.count()}")

# COMMAND ----
# MAGIC %md
# MAGIC ## 8. Grade Completa Offline (Data x Filial x SKU)
# MAGIC
# MAGIC Criamos a grade completa combinando todas as datas com todas as combina√ß√µes filial-SKU.
# MAGIC Esta grade garante que teremos registros para todos os dias, mesmo quando n√£o houve vendas.

# COMMAND ----
# Grade completa (Data x Filial x SKU)
grade_completa_offline_df = calendario_df.crossJoin(chaves_filial_sku_df)

# Agregado com data como DateType para join
vendas_offline_agregadas_com_data_df = vendas_offline_agregadas_df.withColumn("DtAtual_date", F.to_date("DtAtual"))

# COMMAND ----
# MAGIC %md
# MAGIC ## 9. Aplica√ß√£o da Grade Completa Offline
# MAGIC
# MAGIC Aplicamos a grade completa √†s vendas offline, preenchendo com zeros os dias sem vendas.
# MAGIC Esta etapa √© crucial para an√°lises de demanda, pois permite identificar padr√µes de sazonalidade e tend√™ncias.

# COMMAND ----
# Left join + zeros onde n√£o houver venda
vendas_offline_final_df = (
    grade_completa_offline_df.join(
        vendas_offline_agregadas_com_data_df,
        on=["DtAtual_date", "CdSkuLoja", "CdFilial"],
        how="left"
    )
    .withColumn("Receita", F.coalesce(F.col("Receita"), F.lit(0.0)))
    .withColumn("QtMercadoria", F.coalesce(F.col("QtMercadoria"), F.lit(0.0)))
    .withColumn("year_month", F.date_format(F.col("DtAtual_date"), "yyyyMM").cast("int"))
    .withColumn("DtAtual", F.date_format(F.col("DtAtual_date"), "yyyy-MM-dd"))
    .withColumnRenamed("CdSkuLoja", "CdSku")
    .select("DtAtual", "year_month", "CdFilial", "CdSku", "Receita", "QtMercadoria")
    .withColumn(
        "TeveVenda",
        F.when(F.col("QtMercadoria") > 0, F.lit(1)).otherwise(F.lit(0))
    )
    .withColumn("Canal", F.lit("OFFLINE"))
)

print(f"‚úÖ Registros finais OFFLINE: {vendas_offline_final_df.count()}")

# Mostrar amostra dos dados
print("üìã Amostra dos dados OFFLINE:")
display(vendas_offline_final_df.limit(5))

# COMMAND ----
# MAGIC %md
# MAGIC ## 10. Carregamento de Vendas Online (Canais Digitais)
# MAGIC
# MAGIC Carregamos as vendas de canais digitais (e-commerce, marketplace, etc.).
# MAGIC Esta etapa √© importante pois representa um canal de crescimento significativo da empresa.
# MAGIC Aplicamos os mesmos filtros de qualidade dos dados offline.

# COMMAND ----
print(f"üåê Processando vendas ONLINE de {data_inicio_int} at√© {hoje_int}")

# Carregar tabela de vendas rateadas (online)
vendas_rateadas_online_df = (
    spark.table("app_venda.vendafaturadarateada")
    .filter(F.col("NmEstadoMercadoria") != '1 - SALDO')
    .filter(F.col("NmTipoNegocio") != 'LOJA FISICA')  # Excluir loja f√≠sica
    .filter(
        F.col("DtAprovacao").between(data_inicio_int, hoje_int)
        & (F.col("VrOperacao") >= 0)
        & (F.col("VrCustoContabilFilialSku") >= 0)
    )
)

print(f"üìä Registros rateados ONLINE carregados: {vendas_rateadas_online_df.count()}")

# COMMAND ----
# MAGIC %md
# MAGIC ## 11. Unifica√ß√£o dos Dados Online
# MAGIC
# MAGIC Realizamos o mesmo processo de unifica√ß√£o para as vendas online.
# MAGIC Esta etapa garante consist√™ncia no tratamento dos dados entre os canais.

# COMMAND ----
# Unificar dados e aplicar transforma√ß√µes
vendas_online_unificadas_df = (
    vendas_rateadas_online_df
    .join(vendas_nao_rateadas_df.select("ChaveFatos", "QtMercadoria"), on="ChaveFatos")
    .withColumn(
        "year_month",
        F.date_format(
            F.to_date(F.col("DtAprovacao").cast("string"), "yyyyMMdd"), 
            "yyyyMM"
        ).cast("int")
    )
    .withColumnRenamed("CdFilialVenda", "CdFilial")
    .withColumn(
        "DtAtual",
        F.date_format(
            F.to_date(F.col("DtAprovacao").cast("string"), "yyyyMMdd"), 
            "yyyy-MM-dd"
        )
    )
)

print(f"üîó Registros ap√≥s join ONLINE: {vendas_online_unificadas_df.count()}")

# COMMAND ----
# MAGIC %md
# MAGIC ## 12. Agrega√ß√£o das Vendas Online
# MAGIC
# MAGIC Agregamos as vendas online seguindo a mesma l√≥gica das vendas offline.
# MAGIC Esta consist√™ncia √© fundamental para an√°lises comparativas entre canais.

# COMMAND ----
# Agregar por filial, SKU e data
vendas_online_agregadas_df = (
    vendas_online_unificadas_df.groupBy(
        "DtAtual",
        "year_month",
        "CdSkuLoja",
        "CdFilial",
    )
    .agg(
        F.sum("VrOperacao").alias("Receita"),
        F.sum("QtMercadoria").alias("QtMercadoria"),
        F.sum("VrCustoContabilFilialSku").alias("Custo")
    )
)

print(f"üìä Registros ap√≥s agrega√ß√£o ONLINE: {vendas_online_agregadas_df.count()}")

# COMMAND ----
# MAGIC %md
# MAGIC ## 13. Cria√ß√£o da Grade Completa Online
# MAGIC
# MAGIC Criamos a grade completa para vendas online seguindo a mesma l√≥gica das vendas offline.
# MAGIC Esta etapa garante que teremos dados consistentes entre os canais.

# COMMAND ----
# Conjunto de chaves (Filial x SKU) para online
chaves_filial_sku_online_df = (
    vendas_online_unificadas_df
    .select("CdFilial", "CdSkuLoja")
    .dropDuplicates()
)

print(f"üîë Chaves √∫nicas ONLINE (Filial x SKU): {chaves_filial_sku_online_df.count()}")

# Grade completa (Data x Filial x SKU)
grade_completa_online_df = calendario_df.crossJoin(chaves_filial_sku_online_df)

# Agregado com data como DateType para join
vendas_online_agregadas_com_data_df = vendas_online_agregadas_df.withColumn("DtAtual_date", F.to_date("DtAtual"))

# COMMAND ----
# MAGIC %md
# MAGIC ## 14. Aplica√ß√£o da Grade Completa Online
# MAGIC
# MAGIC Aplicamos a grade completa √†s vendas online, preenchendo com zeros os dias sem vendas.
# MAGIC Esta etapa finaliza o processamento das vendas online com a mesma estrutura das vendas offline.

# COMMAND ----
# Left join + zeros onde n√£o houver venda
vendas_online_final_df = (
    grade_completa_online_df.join(
        vendas_online_agregadas_com_data_df,
        on=["DtAtual_date", "CdSkuLoja", "CdFilial"],
        how="left"
    )
    .withColumn("Receita", F.coalesce(F.col("Receita"), F.lit(0.0)))
    .withColumn("QtMercadoria", F.coalesce(F.col("QtMercadoria"), F.lit(0.0)))
    .withColumn("year_month", F.date_format(F.col("DtAtual_date"), "yyyyMM").cast("int"))
    .withColumn("DtAtual", F.date_format(F.col("DtAtual_date"), "yyyy-MM-dd"))
    .withColumnRenamed("CdSkuLoja", "CdSku")
    .select("DtAtual", "year_month", "CdFilial", "CdSku", "Receita", "QtMercadoria")
    .withColumn(
        "TeveVenda",
        F.when(F.col("QtMercadoria") > 0, F.lit(1)).otherwise(F.lit(0))
    )
    .withColumn("Canal", F.lit("ONLINE"))
)

print(f"‚úÖ Registros finais ONLINE: {vendas_online_final_df.count()}")

# Mostrar amostra dos dados
print("üìã Amostra dos dados ONLINE:")
display(vendas_online_final_df.limit(5))

# COMMAND ----
# MAGIC %md
# MAGIC ## 15. Consolida√ß√£o de Vendas Online e Offline
# MAGIC
# MAGIC Unimos os dados de vendas online e offline em uma √∫nica base consolidada.
# MAGIC Esta etapa √© fundamental para an√°lises integradas de demanda e planejamento de estoque.

# COMMAND ----
print("üîÑ Consolidando vendas ONLINE e OFFLINE...")

# Valida√ß√£o de dados
if vendas_offline_final_df.count() == 0 and vendas_online_final_df.count() == 0:
    raise ValueError("Ambos os DataFrames de vendas est√£o vazios")

# Unir os DataFrames
vendas_consolidadas_df = vendas_offline_final_df.union(vendas_online_final_df)

print(f"üìä Total de registros consolidados: {vendas_consolidadas_df.count()}")

# COMMAND ----
# MAGIC %md
# MAGIC ## 16. An√°lise Estat√≠stica por Canal
# MAGIC
# MAGIC Geramos estat√≠sticas por canal para validar a qualidade dos dados consolidados.
# MAGIC Esta an√°lise nos permite identificar padr√µes e validar a consist√™ncia dos dados.

# COMMAND ----
# Mostrar estat√≠sticas por canal
print("üìà Estat√≠sticas por canal:")
estatisticas_por_canal_df = vendas_consolidadas_df.groupBy("Canal").agg(
    F.count("*").alias("Total_Registros"),
    F.sum("Receita").alias("Receita_Total"),
    F.sum("QtMercadoria").alias("Quantidade_Total"),
    F.sum("TeveVenda").alias("Dias_Com_Venda")
)

display(estatisticas_por_canal_df)

# COMMAND ----
# MAGIC %md
# MAGIC ## 17. Adi√ß√£o de Metadados de Processamento
# MAGIC
# MAGIC Adicionamos metadados essenciais para rastreabilidade e auditoria dos dados.
# MAGIC Estes metadados s√£o fundamentais para governan√ßa de dados e troubleshooting.

# COMMAND ----
# Adicionar metadados de processamento
vendas_com_metadados_df = vendas_consolidadas_df.withColumn(
    "DataHoraProcessamento", 
    F.current_timestamp()
).withColumn(
    "DataProcessamento",
    F.current_date()
).withColumn(
    "FonteDados",
    F.lit("app_venda.vendafaturadarateada + vendafaturadanaorateada")
).withColumn(
    "VersaoProcessamento",
    F.lit("1.0")
)

print(f"üìä Registros com metadados: {vendas_com_metadados_df.count()}")

# COMMAND ----
# MAGIC %md
# MAGIC ## 18. Salvamento na Camada Bronze
# MAGIC
# MAGIC Salvamos os dados consolidados na camada Bronze com modo overwrite.
# MAGIC Esta etapa finaliza o processamento e disponibiliza os dados para as pr√≥ximas camadas.

# COMMAND ----
print(f"üíæ Salvando tabela {TABELA_BRONZE_VENDAS} no modo overwrite...")

try:
    # Salvar na camada Bronze
    vendas_com_metadados_df.write \
        .format("delta") \
        .mode("overwrite") \
        .option("overwriteSchema", "true") \
        .saveAsTable(TABELA_BRONZE_VENDAS)
    
    print(f"‚úÖ Tabela {TABELA_BRONZE_VENDAS} salva com sucesso!")
    print(f"üìä Registros salvos: {vendas_com_metadados_df.count()}")
    
except Exception as e:
    print(f"‚ùå Erro ao salvar tabela {TABELA_BRONZE_VENDAS}: {str(e)}")
    raise

# COMMAND ----
# MAGIC %md
# MAGIC ## 19. Valida√ß√£o da Tabela Salva
# MAGIC
# MAGIC Validamos a tabela salva verificando o schema e uma amostra dos dados.
# MAGIC Esta etapa garante que o salvamento foi realizado corretamente.

# COMMAND ----
# Mostrar schema da tabela salva
print("üìã Schema da tabela salva:")
spark.table(TABELA_BRONZE_VENDAS).printSchema()

# Mostrar amostra dos dados salvos
print("üìã Amostra dos dados salvos:")
display(spark.table(TABELA_BRONZE_VENDAS).limit(5))

# COMMAND ----
# MAGIC %md
# MAGIC ## 20. Resumo Final do Processamento
# MAGIC
# MAGIC Apresentamos um resumo final do processamento realizado.
# MAGIC Este resumo √© importante para documentar o sucesso da execu√ß√£o e os resultados obtidos.

# COMMAND ----
print("üéâ Processamento de vendas Bronze conclu√≠do com sucesso!")
print("=" * 80)
print("üìä RESUMO DO PROCESSAMENTO:")
print(f"  ‚Ä¢ Per√≠odo processado: {data_inicio_str} at√© {hoje_str}")
print(f"  ‚Ä¢ Dias de hist√≥rico: {dias_retrocesso}")
print(f"  ‚Ä¢ Registros offline: {vendas_offline_final_df.count():,}")
print(f"  ‚Ä¢ Registros online: {vendas_online_final_df.count():,}")
print(f"  ‚Ä¢ Total consolidado: {vendas_consolidadas_df.count():,}")
print(f"  ‚Ä¢ Tabela de destino: {TABELA_BRONZE_VENDAS}")
print("=" * 80)
print("‚úÖ PROCESSAMENTO CONCLU√çDO COM SUCESSO!")